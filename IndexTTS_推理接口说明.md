# IndexTTS æ¨ç†æ¥å£è¯´æ˜

IndexTTS æ˜¯ä¸€ä¸ªåŸºäº GPT çš„æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰ç³»ç»Ÿï¼Œæä¾›äº†é«˜è´¨é‡çš„è¯­éŸ³åˆæˆèƒ½åŠ›ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨ IndexTTS çš„æ¨ç†æ¥å£ã€‚

## ç›®å½•

- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [IndexTTS ç±»åˆå§‹åŒ–](#indextts-ç±»åˆå§‹åŒ–)
- [æ¨ç†æ–¹æ³•](#æ¨ç†æ–¹æ³•)
  - [infer - æ ‡å‡†æ¨ç†](#infer---æ ‡å‡†æ¨ç†)
  - [infer_fast - å¿«é€Ÿæ¨ç†](#infer_fast---å¿«é€Ÿæ¨ç†)
- [ç”Ÿæˆå‚æ•°è¯¦è§£](#ç”Ÿæˆå‚æ•°è¯¦è§£)
- [ä½¿ç”¨ç¤ºä¾‹](#ä½¿ç”¨ç¤ºä¾‹)
- [æ³¨æ„äº‹é¡¹](#æ³¨æ„äº‹é¡¹)

## å¿«é€Ÿå¼€å§‹

```python
from indextts.infer import IndexTTS

# åˆå§‹åŒ–æ¨¡å‹
tts = IndexTTS(
    cfg_path="checkpoints/config.yaml",
    model_dir="checkpoints",
    is_fp16=True
)

# æ‰§è¡Œæ¨ç†
tts.infer(
    audio_prompt="reference_audio.wav",
    text="æ‚¨å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªè¯­éŸ³åˆæˆç¤ºä¾‹ã€‚",
    output_path="output.wav"
)
```

## IndexTTS ç±»åˆå§‹åŒ–

### æ„é€ å‡½æ•°å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `cfg_path` | str | `"checkpoints/config.yaml"` | é…ç½®æ–‡ä»¶è·¯å¾„ |
| `model_dir` | str | `"checkpoints"` | æ¨¡å‹æ–‡ä»¶ç›®å½• |
| `is_fp16` | bool | `True` | æ˜¯å¦å¯ç”¨ FP16 ç²¾åº¦ï¼ˆä»… GPU æ¨¡å¼ï¼‰ |
| `device` | str/None | `None` | æŒ‡å®šè®¾å¤‡ï¼ˆå¦‚ `"cuda:0"`, `"cpu"`ï¼‰ï¼ŒNone åˆ™è‡ªåŠ¨é€‰æ‹© |
| `use_cuda_kernel` | bool/None | `None` | æ˜¯å¦ä½¿ç”¨ BigVGAN è‡ªå®šä¹‰ CUDA å†…æ ¸ï¼ˆä»… CUDA è®¾å¤‡ï¼‰ |

### è®¾å¤‡é€‰æ‹©ç­–ç•¥

- **è‡ªåŠ¨é€‰æ‹©**ï¼ˆ`device=None`ï¼‰ï¼š
  - ä¼˜å…ˆé€‰æ‹© CUDA è®¾å¤‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
  - å…¶æ¬¡é€‰æ‹© MPS è®¾å¤‡ï¼ˆå¦‚æœå¯ç”¨ï¼ŒmacOSï¼‰
  - æœ€åå›é€€åˆ° CPU
- **æ‰‹åŠ¨æŒ‡å®š**ï¼šå¯ä»¥æŒ‡å®šå…·ä½“è®¾å¤‡å¦‚ `"cuda:0"`, `"cuda:1"`, `"cpu"` ç­‰

### æ€§èƒ½ä¼˜åŒ–é€‰é¡¹

- **FP16 ç²¾åº¦**ï¼šåœ¨ GPU ä¸Šå¯ç”¨å¯æ˜¾è‘—æå‡æ¨ç†é€Ÿåº¦ï¼Œä½† CPU æ¨¡å¼ä¼šè‡ªåŠ¨ç¦ç”¨
- **CUDA å†…æ ¸**ï¼šå¯ç”¨ BigVGAN è‡ªå®šä¹‰ CUDA å†…æ ¸å¯è¿›ä¸€æ­¥ä¼˜åŒ–æ€§èƒ½

## æ¨ç†æ–¹æ³•

IndexTTS æä¾›ä¸¤ç§æ¨ç†æ¨¡å¼ï¼šæ ‡å‡†æ¨ç†ï¼ˆ`infer`ï¼‰å’Œå¿«é€Ÿæ¨ç†ï¼ˆ`infer_fast`ï¼‰ã€‚

### infer - æ ‡å‡†æ¨ç†

é€‚ç”¨äºå¯¹éŸ³è´¨è¦æ±‚è¾ƒé«˜çš„åœºæ™¯ï¼Œæ¨ç†é€Ÿåº¦ç›¸å¯¹è¾ƒæ…¢ä½†éŸ³è´¨æ›´å¥½ã€‚

#### æ–¹æ³•ç­¾å

```python
def infer(
    self, 
    audio_prompt: str, 
    text: str, 
    output_path: str, 
    verbose: bool = False, 
    max_text_tokens_per_sentence: int = 120, 
    **generation_kwargs
) -> str or tuple
```

#### å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `audio_prompt` | str | - | å‚è€ƒéŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆä½œä¸ºè¯­éŸ³é£æ ¼å‚è€ƒï¼‰ |
| `text` | str | - | éœ€è¦åˆæˆçš„æ–‡æœ¬å†…å®¹ |
| `output_path` | str | - | è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚ä¸º None åˆ™è¿”å›éŸ³é¢‘æ•°æ®ï¼‰ |
| `verbose` | bool | `False` | æ˜¯å¦è¾“å‡ºè¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯ |
| `max_text_tokens_per_sentence` | int | `120` | æ¯å¥è¯çš„æœ€å¤§ token æ•°ï¼ˆç”¨äºé•¿æ–‡æœ¬åˆ†å¥ï¼‰ |
| `**generation_kwargs` | - | - | é¢å¤–çš„ç”Ÿæˆå‚æ•°ï¼ˆè§ä¸‹æ–‡è¯¦è§£ï¼‰ |

### infer_fast - å¿«é€Ÿæ¨ç†

é’ˆå¯¹é•¿æ–‡æœ¬ä¼˜åŒ–çš„å¿«é€Ÿæ¨ç†æ¨¡å¼ï¼Œå¯å®ç° 2-10 å€çš„é€Ÿåº¦æå‡ã€‚

#### æ–¹æ³•ç­¾å

```python
def infer_fast(
    self, 
    audio_prompt: str, 
    text: str, 
    output_path: str, 
    verbose: bool = False, 
    max_text_tokens_per_sentence: int = 100, 
    sentences_bucket_max_size: int = 4, 
    **generation_kwargs
) -> str or tuple
```

#### å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `audio_prompt` | str | - | å‚è€ƒéŸ³é¢‘æ–‡ä»¶è·¯å¾„ |
| `text` | str | - | éœ€è¦åˆæˆçš„æ–‡æœ¬å†…å®¹ |
| `output_path` | str | - | è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„ |
| `verbose` | bool | `False` | æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯ |
| `max_text_tokens_per_sentence` | int | `100` | åˆ†å¥çš„æœ€å¤§ token æ•° |
| `sentences_bucket_max_size` | int | `4` | åˆ†å¥åˆ†æ¡¶çš„æœ€å¤§å®¹é‡ |
| `**generation_kwargs` | - | - | é¢å¤–çš„ç”Ÿæˆå‚æ•° |

#### å¿«é€Ÿæ¨ç†ç‰¹æœ‰å‚æ•°

- **`max_text_tokens_per_sentence`**ï¼š
  - è¶Šå°ï¼šbatch è¶Šå¤šï¼Œæ¨ç†é€Ÿåº¦è¶Šå¿«ï¼Œå†…å­˜å ç”¨æ›´å¤šï¼Œå¯èƒ½å½±å“è´¨é‡
  - è¶Šå¤§ï¼šbatch è¶Šå°‘ï¼Œæ¨ç†é€Ÿåº¦è¶Šæ…¢ï¼Œå†…å­˜å’Œè´¨é‡æ›´æ¥è¿‘æ ‡å‡†æ¨ç†

- **`sentences_bucket_max_size`**ï¼š
  - è¶Šå¤§ï¼šbucket æ•°é‡è¶Šå°‘ï¼Œbatch è¶Šå¤šï¼Œæ¨ç†é€Ÿåº¦è¶Šå¿«ï¼Œå†…å­˜å ç”¨æ›´å¤š
  - è¶Šå°ï¼šbucket æ•°é‡è¶Šå¤šï¼Œbatch è¶Šå°‘ï¼Œæ¨ç†é€Ÿåº¦è¶Šæ…¢ï¼Œè´¨é‡æ›´æ¥è¿‘æ ‡å‡†æ¨ç†

## ç”Ÿæˆå‚æ•°è¯¦è§£

ä»¥ä¸‹å‚æ•°å¯é€šè¿‡ `**generation_kwargs` ä¼ é€’ï¼š

### é‡‡æ ·ç›¸å…³å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `do_sample` | bool | `True` | æ˜¯å¦ä½¿ç”¨éšæœºé‡‡æ ·ï¼ˆFalse åˆ™ä½¿ç”¨è´ªå¿ƒæœç´¢ï¼‰ |
| `temperature` | float | `1.0` | é‡‡æ ·æ¸©åº¦ï¼Œæ§åˆ¶ç”Ÿæˆçš„éšæœºæ€§ï¼ˆ0.1-2.0ï¼‰ |
| `top_p` | float | `0.8` | Top-p æ ¸é‡‡æ ·å‚æ•°ï¼ˆ0.1-1.0ï¼‰ |
| `top_k` | int | `30` | Top-k é‡‡æ ·å‚æ•° |

### Beam Search å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `num_beams` | int | `3` | Beam search çš„ beam æ•°é‡ |
| `length_penalty` | float | `0.0` | é•¿åº¦æƒ©ç½šç³»æ•° |

### è´¨é‡æ§åˆ¶å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `repetition_penalty` | float | `10.0` | é‡å¤æƒ©ç½šç³»æ•°ï¼Œé˜²æ­¢ç”Ÿæˆé‡å¤å†…å®¹ |
| `max_mel_tokens` | int | `600` | æœ€å¤§ç”Ÿæˆçš„ mel token æ•°é‡ |

## è¯­éŸ³é•¿åº¦æ§åˆ¶

IndexTTS æä¾›äº†å¤šä¸ªå‚æ•°æ¥ç²¾ç¡®æ§åˆ¶ç”Ÿæˆè¯­éŸ³çš„é•¿åº¦ï¼Œé€‚åº”ä¸åŒçš„åº”ç”¨åœºæ™¯éœ€æ±‚ã€‚

### æ ¸å¿ƒé•¿åº¦æ§åˆ¶å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ | å½±å“èŒƒå›´ |
|------|------|--------|------|----------|
| `max_mel_tokens` | int | `600` | æœ€å¤§ç”Ÿæˆçš„ mel token æ•°é‡ | ç›´æ¥æ§åˆ¶å•å¥è¯­éŸ³æœ€å¤§é•¿åº¦ |
| `length_penalty` | float | `0.0` | é•¿åº¦æƒ©ç½šç³»æ•° | å½±å“ beam search çš„é•¿åº¦åå¥½ |
| `max_text_tokens_per_sentence` | int | `120`/`100` | æ¯å¥è¯çš„æœ€å¤§æ–‡æœ¬ token æ•° | æ§åˆ¶åˆ†å¥ç²’åº¦ï¼Œé—´æ¥å½±å“è¯­éŸ³é•¿åº¦ |

### é•¿åº¦æ§åˆ¶ç­–ç•¥è¯¦è§£

#### 1. mel token ä¸è¯­éŸ³æ—¶é•¿çš„å…³ç³»

```
è¯­éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰ â‰ˆ mel_tokens Ã— 0.0106
```

å¸¸ç”¨çš„ `max_mel_tokens` é…ç½®ï¼š

| ç›®æ ‡è¯­éŸ³é•¿åº¦ | æ¨è max_mel_tokens | è¯´æ˜ |
|-------------|-------------------|------|
| çŸ­å¥ï¼ˆ1-3ç§’ï¼‰ | 200-400 | é€‚åˆå¿«é€Ÿå“åº”åœºæ™¯ |
| ä¸­ç­‰ï¼ˆ3-6ç§’ï¼‰ | 400-600 | é»˜è®¤é…ç½®ï¼Œå¹³è¡¡è´¨é‡å’Œæ•ˆç‡ |
| é•¿å¥ï¼ˆ6-12ç§’ï¼‰ | 600-1200 | é€‚åˆæœ—è¯»ã€è®²è§£ç­‰åœºæ™¯ |
| è¶…é•¿ï¼ˆ12ç§’ä»¥ä¸Šï¼‰ | 1200+ | éœ€è¦è¶³å¤Ÿçš„ GPU å†…å­˜ |

> âš ï¸ **é‡è¦æé†’ï¼šæˆªæ–­é£é™©**
> 
> `max_mel_tokens` è®¾ç½®è¿‡å°æ˜¯å¯¼è‡´**è¯­éŸ³æˆªæ–­**çš„ä¸»è¦åŸå› ï¼å½“ç”Ÿæˆçš„ mel token æ•°é‡è¾¾åˆ°é™åˆ¶æ—¶ï¼Œæ¨¡å‹ä¼šå¼ºåˆ¶åœæ­¢ç”Ÿæˆï¼Œå¯¼è‡´ï¼š
> - âŒ **è¯­éŸ³ä¸å®Œæ•´**ï¼šå¥å­å¯èƒ½è¯´åˆ°ä¸€åŠå°±çªç„¶åœæ­¢
> - âŒ **éŸ³è´¨ä¸‹é™**ï¼šçªç„¶ä¸­æ–­ä¼šè®©è¯­éŸ³å¬èµ·æ¥ä¸è‡ªç„¶  
> - âŒ **è¯­ä¹‰ç¼ºå¤±**ï¼šé‡è¦ä¿¡æ¯å¯èƒ½è¢«æˆªæ–­ä¸¢å¤±
>
> **å¦‚ä½•è¯†åˆ«æˆªæ–­ï¼š**
> ```
> WARN: generation stopped due to exceeding max_mel_tokens (600)
> ```
> çœ‹åˆ°æ­¤è­¦å‘Šè¯´æ˜å‘ç”Ÿäº†æˆªæ–­ï¼Œéœ€è¦è°ƒæ•´å‚æ•°ã€‚

#### max_mel_tokens å®‰å…¨é…ç½®æŒ‡å—

**ğŸ“‹ é…ç½®æ£€æŸ¥æ¸…å•ï¼š**

âœ… **æ–‡æœ¬é•¿åº¦è¯„ä¼°**
```python
# å¿«é€Ÿè¯„ä¼°ï¼šé¢„ä¼°æ‰€éœ€çš„ mel tokens
text_chars = len(your_text)
estimated_tokens = text_chars * 0.5  # ä¿å®ˆä¼°ç®—
recommended_max = int(estimated_tokens * 1.3)  # åŠ 30%å®‰å…¨ä½™é‡
print(f"æ¨è max_mel_tokens: {recommended_max}")
```

**ğŸ’¡ æœ€ä½³å®è·µæ€»ç»“ï¼š**

1. **é¢„ä¼°ä¼˜äºçŒœæµ‹**ï¼šä½¿ç”¨è®¡ç®—å…¬å¼é¢„ä¼°æ‰€éœ€ tokensï¼Œé¿å…ç›²ç›®è®¾ç½®
2. **å®å¤§å‹¿å°**ï¼šè®¾ç½®å®‰å…¨ä½™é‡ï¼Œé¿å…æˆªæ–­æ¯”ç•¥å¾®æµªè´¹å†…å­˜æ›´é‡è¦
3. **åˆ†æ®µå¤„ç†**ï¼šå¯¹äºè¶…é•¿æ–‡æœ¬ï¼Œè€ƒè™‘ä½¿ç”¨ `infer_fast` æˆ–æ‰‹åŠ¨åˆ†æ®µ
4. **ç›‘æ§è­¦å‘Š**ï¼šå§‹ç»ˆå…³æ³¨æˆªæ–­è­¦å‘Šï¼ŒåŠæ—¶è°ƒæ•´å‚æ•°
5. **åŠ¨æ€è°ƒæ•´**ï¼šæ ¹æ®ä¸åŒæ–‡æœ¬ç±»å‹å’Œé•¿åº¦åŠ¨æ€è°ƒæ•´å‚æ•°

#### 2. é•¿åº¦æƒ©ç½šæœºåˆ¶

`length_penalty` å‚æ•°æ§åˆ¶æ¨¡å‹å¯¹ç”Ÿæˆé•¿åº¦çš„åå¥½ï¼š

```python
# é¼“åŠ±ç”Ÿæˆè¾ƒé•¿çš„è¯­éŸ³
length_penalty = 1.0  # æ­£å€¼é¼“åŠ±é•¿åºåˆ—

# é¼“åŠ±ç”Ÿæˆè¾ƒçŸ­çš„è¯­éŸ³  
length_penalty = -0.5  # è´Ÿå€¼é¼“åŠ±çŸ­åºåˆ—

# ä¸­æ€§è®¾ç½®ï¼ˆé»˜è®¤ï¼‰
length_penalty = 0.0  # ä¸æ–½åŠ é•¿åº¦åå¥½
```

> âš ï¸ **é‡è¦è¯´æ˜**ï¼š
> æ ¹æ® HuggingFace Transformers çš„æ ‡å‡†å®ç°ï¼š
> - **æ­£å€¼** (`length_penalty > 0`)ï¼š**é¼“åŠ±è¾ƒé•¿çš„è¯­éŸ³ç”Ÿæˆ**
> - **è´Ÿå€¼** (`length_penalty < 0`)ï¼š**é¼“åŠ±è¾ƒçŸ­çš„è¯­éŸ³ç”Ÿæˆ**  
> - **é›¶å€¼** (`length_penalty = 0`)ï¼šä¸æ–½åŠ é•¿åº¦åå¥½

#### 3. æ–‡æœ¬åˆ†å¥å¯¹é•¿åº¦çš„å½±å“

`max_text_tokens_per_sentence` é€šè¿‡æ§åˆ¶åˆ†å¥ç²’åº¦æ¥é—´æ¥å½±å“è¯­éŸ³é•¿åº¦ï¼š

```python
# ç»†ç²’åº¦åˆ†å¥ - ç”Ÿæˆå¤šä¸ªçŸ­éŸ³é¢‘ç‰‡æ®µ
max_text_tokens_per_sentence = 50

# ç²—ç²’åº¦åˆ†å¥ - ç”Ÿæˆè¾ƒé•¿çš„è¿ç»­éŸ³é¢‘
max_text_tokens_per_sentence = 150
```

### é•¿åº¦æ§åˆ¶é…ç½®ç¤ºä¾‹

#### çŸ­éŸ³é¢‘é…ç½®ï¼ˆé€‚åˆå¯¹è¯ã€æç¤ºéŸ³ï¼‰
```python
short_audio_config = {
    "max_mel_tokens": 300,
    "length_penalty": -0.5,  # é¼“åŠ±è¾ƒçŸ­ç”Ÿæˆ
    "max_text_tokens_per_sentence": 60,
    "temperature": 0.8,
    "num_beams": 3
}

tts.infer(
    audio_prompt="reference.wav",
    text="ç®€çŸ­çš„æç¤ºä¿¡æ¯ã€‚",
    output_path="short_audio.wav",
    **short_audio_config
)
```

#### ä¸­ç­‰é•¿åº¦é…ç½®ï¼ˆé€‚åˆæ–°é—»ã€æ•…äº‹ï¼‰
```python
medium_audio_config = {
    "max_mel_tokens": 800,
    "length_penalty": 0.0,  # ä¸­æ€§é•¿åº¦åå¥½
    "max_text_tokens_per_sentence": 100,
    "temperature": 0.7,
    "num_beams": 4
}
```

#### é•¿éŸ³é¢‘é…ç½®ï¼ˆé€‚åˆæœ—è¯»ã€æ¼”è®²ï¼‰
```python
long_audio_config = {
    "max_mel_tokens": 1500,
    "length_penalty": 0.3,  # é¼“åŠ±è¾ƒé•¿ç”Ÿæˆ
    "max_text_tokens_per_sentence": 150,
    "temperature": 0.6,
    "num_beams": 5,
    "repetition_penalty": 12.0  # é¿å…é•¿éŸ³é¢‘ä¸­çš„é‡å¤
}
```

#### å¿«é€Ÿæ¨ç†ä¸­çš„é•¿åº¦æ§åˆ¶
```python
# é•¿æ–‡æœ¬å¿«é€Ÿæ¨ç†ï¼Œç²¾ç¡®æ§åˆ¶æ¯ä¸ªç‰‡æ®µé•¿åº¦
tts.infer_fast(
    audio_prompt="reference.wav",
    text=long_text,
    output_path="output.wav",
    max_text_tokens_per_sentence=80,  # æ§åˆ¶å•å¥é•¿åº¦
    sentences_bucket_max_size=4,      # æ§åˆ¶æ‰¹å¤„ç†å¤§å°
    max_mel_tokens=600,               # æ§åˆ¶æœ€å¤§ç”Ÿæˆé•¿åº¦
    length_penalty=0.1                # è½»å¾®é¼“åŠ±è¾ƒé•¿ç”Ÿæˆ
)
```

### é•¿åº¦æ§åˆ¶æœ€ä½³å®è·µ

#### 1. æ ¹æ®å†…å®¹ç±»å‹è°ƒæ•´å‚æ•°

```python
# æ–°é—»æ’­æŠ¥ - ç¨³å®šçš„ä¸­ç­‰é•¿åº¦
news_config = {
    "max_mel_tokens": 700,
    "length_penalty": 0.2,  # è½»å¾®é¼“åŠ±è¾ƒé•¿è¯­éŸ³
    "max_text_tokens_per_sentence": 90
}

# æœ‰å£°ä¹¦æœ—è¯» - è¾ƒé•¿è¿è´¯ç‰‡æ®µ
audiobook_config = {
    "max_mel_tokens": 1200,
    "length_penalty": 0.4,  # é¼“åŠ±è¾ƒé•¿è¯­éŸ³
    "max_text_tokens_per_sentence": 140
}

# æ™ºèƒ½åŠ©æ‰‹å›å¤ - ç®€æ´æ˜äº†
assistant_config = {
    "max_mel_tokens": 400,
    "length_penalty": -0.3,  # é¼“åŠ±è¾ƒçŸ­è¯­éŸ³
    "max_text_tokens_per_sentence": 70
}
```

#### 2. åŠ¨æ€é•¿åº¦è°ƒæ•´

```python
def get_length_config(text_length):
    """æ ¹æ®æ–‡æœ¬é•¿åº¦åŠ¨æ€è°ƒæ•´å‚æ•°"""
    if text_length < 50:
        return {
            "max_mel_tokens": 300,
            "length_penalty": -0.2,  # çŸ­æ–‡æœ¬é¼“åŠ±ç®€æ´
            "max_text_tokens_per_sentence": 50
        }
    elif text_length < 200:
        return {
            "max_mel_tokens": 600,
            "length_penalty": 0.1,   # ä¸­ç­‰æ–‡æœ¬è½»å¾®é¼“åŠ±è¾ƒé•¿è¯­éŸ³
            "max_text_tokens_per_sentence": 80
        }
    else:
        return {
            "max_mel_tokens": 1000,
            "length_penalty": 0.3,   # é•¿æ–‡æœ¬é¼“åŠ±è¾ƒé•¿è¯­éŸ³
            "max_text_tokens_per_sentence": 120
        }

# ä½¿ç”¨ç¤ºä¾‹
text = "æ‚¨çš„æ–‡æœ¬å†…å®¹..."
config = get_length_config(len(text))
tts.infer(audio_prompt="ref.wav", text=text, output_path="out.wav", **config)
```

### é•¿åº¦æ§åˆ¶å¸¸è§é—®é¢˜

#### 1. ç”Ÿæˆåœæ­¢è­¦å‘Š
```
WARN: generation stopped due to exceeding max_mel_tokens (600)
```

**è§£å†³æ–¹æ¡ˆï¼š**
- å¢å¤§ `max_mel_tokens` å‚æ•°
- å‡å° `max_text_tokens_per_sentence` è¿›è¡Œæ›´ç»†åˆ†å¥
- æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«è¿‡é•¿å¥å­

#### 2. éŸ³é¢‘è¿‡çŸ­æˆ–æˆªæ–­

**å¯èƒ½åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š**
```python
# é—®é¢˜ï¼šéŸ³é¢‘æ„å¤–æˆªæ–­
# è§£å†³ï¼šå¢åŠ æœ€å¤§é•¿åº¦é™åˆ¶
config = {
    "max_mel_tokens": 1000,  # å¢å¤§é™åˆ¶
    "length_penalty": 0.2    # é¼“åŠ±å®Œæ•´ç”Ÿæˆ
}

# é—®é¢˜ï¼šéŸ³é¢‘è¿‡çŸ­
# è§£å†³ï¼šé¼“åŠ±æ›´é•¿çš„ç”Ÿæˆ
config = {
    "length_penalty": 0.3,   # æ­£å€¼é¼“åŠ±è¾ƒé•¿ç”Ÿæˆ
    "temperature": 0.6       # é™ä½éšæœºæ€§
}
```

#### 3. å†…å­˜ä¸è¶³é—®é¢˜

å½“ `max_mel_tokens` è®¾ç½®è¿‡å¤§æ—¶å¯èƒ½å¯¼è‡´å†…å­˜ä¸è¶³ï¼š

```python
# GPU å†…å­˜ä¼˜åŒ–é…ç½®
memory_efficient_config = {
    "max_mel_tokens": 800,                    # é€‚ä¸­çš„é•¿åº¦é™åˆ¶
    "sentences_bucket_max_size": 2,           # å‡å°æ‰¹å¤„ç†å¤§å°
    "max_text_tokens_per_sentence": 80        # æ›´ç»†çš„åˆ†å¥
}
```

### é•¿åº¦é¢„ä¼°å·¥å…·

```python
def estimate_audio_duration(text, avg_tokens_per_second=94):
    """
    ä¼°ç®—éŸ³é¢‘æ—¶é•¿
    
    Args:
        text: è¾“å…¥æ–‡æœ¬
        avg_tokens_per_second: å¹³å‡æ¯ç§’ mel tokensï¼ˆçº¦94ï¼‰
    
    Returns:
        estimated_duration: é¢„ä¼°æ—¶é•¿ï¼ˆç§’ï¼‰
    """
    # ç²—ç•¥ä¼°ç®—ï¼šä¸­æ–‡çº¦ 2 å­—ç¬¦/tokenï¼Œè‹±æ–‡çº¦ 4 å­—ç¬¦/token
    char_count = len(text)
    estimated_tokens = char_count * 0.5  # ä¿å®ˆä¼°è®¡
    estimated_duration = estimated_tokens / avg_tokens_per_second
    
    return estimated_duration

# ä½¿ç”¨ç¤ºä¾‹
text = "è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºä¼°ç®—ç”Ÿæˆçš„éŸ³é¢‘é•¿åº¦ã€‚"
duration = estimate_audio_duration(text)
print(f"é¢„ä¼°éŸ³é¢‘æ—¶é•¿: {duration:.2f} ç§’")

# æ ¹æ®é¢„ä¼°æ—¶é•¿è®¾ç½® max_mel_tokens
recommended_max_tokens = int(duration * 94 * 1.2)  # å¢åŠ  20% ä½™é‡
```

### å‚æ•°é…ç½®å»ºè®®

#### é«˜è´¨é‡é…ç½®
```python
generation_kwargs = {
    "do_sample": True,
    "temperature": 0.7,
    "top_p": 0.9,
    "top_k": 50,
    "num_beams": 5,
    "repetition_penalty": 15.0,
    "max_mel_tokens": 800
}
```

#### å¿«é€Ÿé…ç½®
```python
generation_kwargs = {
    "do_sample": True,
    "temperature": 1.0,
    "top_p": 0.8,
    "top_k": 30,
    "num_beams": 1,
    "repetition_penalty": 5.0,
    "max_mel_tokens": 400
}
```

#### ç¨³å®šé…ç½®
```python
generation_kwargs = {
    "do_sample": False,  # ä½¿ç”¨è´ªå¿ƒæœç´¢
    "num_beams": 3,
    "repetition_penalty": 10.0,
    "max_mel_tokens": 600
}
```

## ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ä½¿ç”¨

```python
from indextts.infer import IndexTTS

# åˆå§‹åŒ–
tts = IndexTTS()

# æ ‡å‡†æ¨ç†
output_file = tts.infer(
    audio_prompt="reference.wav",
    text="è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ã€‚",
    output_path="output.wav",
    verbose=True
)
print(f"éŸ³é¢‘å·²ä¿å­˜åˆ°: {output_file}")
```

### å¿«é€Ÿæ¨ç†ï¼ˆé€‚åˆé•¿æ–‡æœ¬ï¼‰

```python
long_text = """
äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•æ—¥æ–°æœˆå¼‚ï¼Œè¯­éŸ³åˆæˆä½œä¸ºå…¶ä¸­çš„é‡è¦åˆ†æ”¯ï¼Œ
å·²ç»åœ¨è¯¸å¤šé¢†åŸŸå¾—åˆ°äº†å¹¿æ³›åº”ç”¨ã€‚IndexTTS ä½œä¸ºæ–°ä¸€ä»£çš„
æ–‡æœ¬è½¬è¯­éŸ³ç³»ç»Ÿï¼Œå…·æœ‰éŸ³è´¨è‡ªç„¶ã€å“åº”è¿…é€Ÿçš„ç‰¹ç‚¹ã€‚
"""

tts.infer_fast(
    audio_prompt="reference.wav",
    text=long_text,
    output_path="long_output.wav",
    max_text_tokens_per_sentence=80,
    sentences_bucket_max_size=6
)
```

### è‡ªå®šä¹‰ç”Ÿæˆå‚æ•°

```python
# é«˜è´¨é‡ç”Ÿæˆ
tts.infer(
    audio_prompt="reference.wav",
    text="éœ€è¦é«˜è´¨é‡åˆæˆçš„æ–‡æœ¬ã€‚",
    output_path="high_quality.wav",
    do_sample=True,
    temperature=0.6,
    top_p=0.95,
    num_beams=5,
    repetition_penalty=15.0,
    max_mel_tokens=1000
)
```

### è¿”å›éŸ³é¢‘æ•°æ®è€Œéä¿å­˜æ–‡ä»¶

```python
# ä¸æŒ‡å®š output_pathï¼Œç›´æ¥è¿”å›éŸ³é¢‘æ•°æ®
sample_rate, audio_data = tts.infer(
    audio_prompt="reference.wav",
    text="æµ‹è¯•æ–‡æœ¬",
    output_path=None  # è¿”å›éŸ³é¢‘æ•°æ®
)

# å¯ä»¥è¿›ä¸€æ­¥å¤„ç†éŸ³é¢‘æ•°æ®
print(f"é‡‡æ ·ç‡: {sample_rate}, éŸ³é¢‘å½¢çŠ¶: {audio_data.shape}")
```

### æ‰¹é‡å¤„ç†

```python
texts = [
    "ç¬¬ä¸€æ®µæ–‡æœ¬ã€‚",
    "ç¬¬äºŒæ®µæ–‡æœ¬ã€‚", 
    "ç¬¬ä¸‰æ®µæ–‡æœ¬ã€‚"
]

for i, text in enumerate(texts):
    tts.infer_fast(
        audio_prompt="reference.wav",
        text=text,
        output_path=f"output_{i}.wav"
    )
```

## æ³¨æ„äº‹é¡¹

### æ€§èƒ½ä¼˜åŒ–

1. **å‚è€ƒéŸ³é¢‘ç¼“å­˜**ï¼šIndexTTS ä¼šè‡ªåŠ¨ç¼“å­˜å‚è€ƒéŸ³é¢‘çš„ç‰¹å¾ï¼Œè¿ç»­ä½¿ç”¨ç›¸åŒå‚è€ƒéŸ³é¢‘æ—¶ä¼šè·³è¿‡é‡å¤è®¡ç®—
2. **GPU å†…å­˜ç®¡ç†**ï¼šæ¨ç†å®Œæˆåä¼šè‡ªåŠ¨æ¸…ç† GPU ç¼“å­˜
3. **é•¿æ–‡æœ¬å¤„ç†**ï¼šå»ºè®®ä½¿ç”¨ `infer_fast` æ–¹æ³•å¤„ç†è¶…è¿‡ 100 å­—çš„æ–‡æœ¬

### å‚æ•°è°ƒä¼˜

1. **éŸ³è´¨ vs é€Ÿåº¦**ï¼š
   - è¿½æ±‚éŸ³è´¨ï¼šä½¿ç”¨ `infer` æ–¹æ³•ï¼Œå¢å¤§ `num_beams`ï¼Œé™ä½ `temperature`
   - è¿½æ±‚é€Ÿåº¦ï¼šä½¿ç”¨ `infer_fast` æ–¹æ³•ï¼Œå‡å° `max_text_tokens_per_sentence`

2. **å†…å­˜ä¼˜åŒ–**ï¼š
   - GPU å†…å­˜ä¸è¶³æ—¶ï¼Œå‡å° `sentences_bucket_max_size`
   - å‡å° `max_mel_tokens` å¯é™ä½å†…å­˜å ç”¨

3. **è´¨é‡æ§åˆ¶**ï¼š
   - å¢å¤§ `repetition_penalty` å¯å‡å°‘é‡å¤
   - è°ƒæ•´ `temperature` æ§åˆ¶ç”Ÿæˆçš„å¤šæ ·æ€§

### å¸¸è§é—®é¢˜

1. **ç”Ÿæˆåœæ­¢è­¦å‘Š**ï¼šå¦‚æœçœ‹åˆ°è¶…å‡º `max_mel_tokens` çš„è­¦å‘Šï¼Œå¯ä»¥ï¼š
   - å¢å¤§ `max_mel_tokens` å‚æ•°
   - å‡å° `max_text_tokens_per_sentence` è¿›è¡Œæ›´ç»†ç²’åº¦çš„åˆ†å¥

2. **CUDA å†…æ ¸åŠ è½½å¤±è´¥**ï¼šè¿™ä¸ä¼šå½±å“åŠŸèƒ½ï¼Œåªæ˜¯æ€§èƒ½ç•¥æœ‰ä¸‹é™ï¼Œå¯é€šè¿‡é‡æ–°å®‰è£…è§£å†³

3. **DeepSpeed åŠ è½½å¤±è´¥**ï¼šç³»ç»Ÿä¼šè‡ªåŠ¨å›é€€åˆ°æ ‡å‡†æ¨ç†ï¼Œä¸å½±å“æ­£å¸¸ä½¿ç”¨

### ç¯å¢ƒè¦æ±‚

- Python 3.7+
- PyTorch 1.8+
- CUDA 11.0+ï¼ˆå¦‚ä½¿ç”¨ GPUï¼‰
- è¶³å¤Ÿçš„å†…å­˜ï¼ˆCPU æ¨¡å¼éœ€è¦æ›´å¤šå†…å­˜ï¼‰

---

æ›´å¤šè¯¦ç»†ä¿¡æ¯è¯·å‚è€ƒé¡¹ç›®çš„å®˜æ–¹æ–‡æ¡£å’Œç¤ºä¾‹ä»£ç ã€‚ 